{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functools\n",
    "import keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/6l9k0t7n045f_gx40s7flt380000gn/T/ipykernel_82869/3146159652.py:19: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  .str.replace('(', '') \\\n",
      "/var/folders/vr/6l9k0t7n045f_gx40s7flt380000gn/T/ipykernel_82869/3146159652.py:20: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  .str.replace(')', '') \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>human_written</th>\n",
       "      <th>ai_written</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>max_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pneumonia: Differential Diagnosis and Primary ...</td>\n",
       "      <td>Penetration of pathogens of pneumonia in the r...</td>\n",
       "      <td>Pneumonia is a common respiratory infection th...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relevance and Significance of Communication Te...</td>\n",
       "      <td>The relevance and significance of communicatio...</td>\n",
       "      <td>Communication technology has become an integra...</td>\n",
       "      <td>Persuasive</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technological Objects and Their Capabilities</td>\n",
       "      <td>An innovative home system is one of the unique...</td>\n",
       "      <td>Technological objects have become an integral ...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philosophy Teaching and Learning Motivation</td>\n",
       "      <td>Teaching and learning philosophy can be a chal...</td>\n",
       "      <td>Teaching and learning philosophy can be a chal...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buddhism and Hinduism: Religious Differences</td>\n",
       "      <td>Buddhism and Hinduism have the same roots. Nev...</td>\n",
       "      <td>Buddhism and Hinduism are two major religions ...</td>\n",
       "      <td>Compare &amp; Contrast</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         essay_title  \\\n",
       "0  Pneumonia: Differential Diagnosis and Primary ...   \n",
       "1  Relevance and Significance of Communication Te...   \n",
       "2      Technological Objects and Their Capabilities    \n",
       "3        Philosophy Teaching and Learning Motivation   \n",
       "4       Buddhism and Hinduism: Religious Differences   \n",
       "\n",
       "                                       human_written  \\\n",
       "0  Penetration of pathogens of pneumonia in the r...   \n",
       "1  The relevance and significance of communicatio...   \n",
       "2  An innovative home system is one of the unique...   \n",
       "3  Teaching and learning philosophy can be a chal...   \n",
       "4  Buddhism and Hinduism have the same roots. Nev...   \n",
       "\n",
       "                                          ai_written                type  \\\n",
       "0  Pneumonia is a common respiratory infection th...          Expository   \n",
       "1  Communication technology has become an integra...          Persuasive   \n",
       "2  Technological objects have become an integral ...          Expository   \n",
       "3  Teaching and learning philosophy can be a chal...          Expository   \n",
       "4  Buddhism and Hinduism are two major religions ...  Compare & Contrast   \n",
       "\n",
       "   min_word_count  max_word_count  \n",
       "0             150             200  \n",
       "1             150             200  \n",
       "2             150             200  \n",
       "3             150             200  \n",
       "4             150             200  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_WORD_COUNT = 'Min Word Count'\n",
    "MAX_WORD_COUNT = 'Max Word Count'\n",
    "\n",
    "df200 = pd.read_csv('resources/essays200.csv').drop('Unnamed: 4', axis=1)\n",
    "df200[MIN_WORD_COUNT] = 150\n",
    "df200[MAX_WORD_COUNT] = 200\n",
    "df500 = pd.read_csv('resources/essays500.csv').drop('Unnamed: 4', axis=1) \n",
    "df500[MIN_WORD_COUNT] = 500\n",
    "df500[MAX_WORD_COUNT] = 600\n",
    "df1000 = pd.read_csv('resources/essays1000.csv').drop('Unnamed: 4', axis=1)\n",
    "df1000[MIN_WORD_COUNT] = 800\n",
    "df1000[MAX_WORD_COUNT] = 1200\n",
    "\n",
    "df = pd.concat([df200, df500, df1000])\n",
    "df.columns = df.columns \\\n",
    "    .str.strip() \\\n",
    "    .str.lower() \\\n",
    "    .str.replace(' ', '_') \\\n",
    "    .str.replace('(', '') \\\n",
    "    .str.replace(')', '') \\\n",
    "    .str.replace('-','_') \\\n",
    "    .map(lambda x: 'x'+x if x in keyword.kwlist else x )\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_df = df.melt(id_vars=['essay_title', 'type', 'min_word_count'], value_vars=['human_written', 'ai_written'], var_name='source', value_name='essay')\n",
    "\n",
    "def convert_label(label):\n",
    "    return 1 if label == 'human_written' else 0\n",
    "\n",
    "melted_df['labels'] = melted_df['source'].apply(convert_label)\n",
    "\n",
    "melted_df = melted_df.sort_values(by=['source', 'essay_title']).reset_index()\n",
    "melted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>source</th>\n",
       "      <th>essay</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Americans in the Revolutionary Era</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>The American Revolution is typically depicted ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Legalization of Marijuana in the United States</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>150</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Legalization of marijuana in the United States...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inclusive Educationâ€™ Benefits</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Inclusive education is a type of education sys...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commercial Uses of Data Mining</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>Data mining is a computer-based classification...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mathematics â€“ Concept of Multiplication</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>In understanding multiplication, it is essenti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      essay_title           type  \\\n",
       "0        Black Americans in the Revolutionary Era     Expository   \n",
       "1  Legalization of Marijuana in the United States  Argumentative   \n",
       "2                   Inclusive Educationâ€™ Benefits  Argumentative   \n",
       "3                  Commercial Uses of Data Mining     Expository   \n",
       "4         Mathematics â€“ Concept of Multiplication     Expository   \n",
       "\n",
       "   min_word_count         source  \\\n",
       "0             800  human_written   \n",
       "1             150     ai_written   \n",
       "2             800     ai_written   \n",
       "3             800  human_written   \n",
       "4             800  human_written   \n",
       "\n",
       "                                               essay  labels  \n",
       "0  The American Revolution is typically depicted ...       1  \n",
       "1  Legalization of marijuana in the United States...       0  \n",
       "2  Inclusive education is a type of education sys...       0  \n",
       "3  Data mining is a computer-based classification...       1  \n",
       "4  In understanding multiplication, it is essenti...       1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([melted_df[:60], melted_df[75:135]])\n",
    "test_df = pd.concat([melted_df[60:75], melted_df[135:]])\n",
    "\n",
    "shuffled_train_df = train_df.sample(frac=1).reset_index().drop(['index', 'level_0'], axis=1)\n",
    "shuffled_test_df = test_df.sample(frac=1).reset_index().drop(['index', 'level_0'], axis=1)\n",
    "shuffled_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "NGRAM_RANGE = (2, 7)\n",
    "\n",
    "TOP_K = 15000\n",
    "\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "MIN_DOCUMENT_FREQUENCY = 7\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
    "    \"\"\"Vectorizes texts as n-gram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE, \n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE, \n",
    "            'stop_words': 'english',\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    x_val = vectorizer.transform(val_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train).astype('float32')\n",
    "    x_val = selector.transform(x_val).astype('float32')\n",
    "    return x_train, x_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2072: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.738835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0         0.0        0.0   0.000000        0.0        0.0        0.0   \n",
       "1         0.0        0.0   0.000000        0.0        0.0        0.0   \n",
       "2         0.0        0.5   0.000000        0.0        0.5        0.0   \n",
       "3         0.0        0.0   0.000000        0.0        0.0        0.0   \n",
       "4         0.0        0.0   0.000000        0.0        0.0        0.0   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "25        0.0        0.0   0.000000        0.0        0.0        0.0   \n",
       "26        0.0        0.0   0.000000        0.0        0.0        0.0   \n",
       "27        0.0        0.0   0.054639        0.0        0.0        0.0   \n",
       "28        0.0        0.0   0.000000        0.0        0.0        0.0   \n",
       "29        0.0        0.0   0.000000        0.0        0.0        0.0   \n",
       "\n",
       "    feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0         0.0        0.0        0.0   0.000000         0.0         0.0   \n",
       "1         0.0        0.0        0.0   0.000000         0.0         0.0   \n",
       "2         0.0        0.0        0.5   0.000000         0.0         0.0   \n",
       "3         0.0        0.0        0.0   0.000000         0.0         0.0   \n",
       "4         0.0        0.0        0.0   0.000000         0.0         0.0   \n",
       "..        ...        ...        ...        ...         ...         ...   \n",
       "25        0.0        0.0        0.0   0.000000         0.0         0.0   \n",
       "26        0.0        0.0        0.0   0.000000         0.0         0.0   \n",
       "27        0.0        0.0        0.0   0.671668         0.0         0.0   \n",
       "28        0.0        0.0        0.0   0.000000         0.0         0.0   \n",
       "29        0.0        0.0        0.0   0.000000         0.0         0.0   \n",
       "\n",
       "    feature_12  feature_13  feature_14  \n",
       "0     0.000000         0.0         0.0  \n",
       "1     0.000000         0.0         1.0  \n",
       "2     0.000000         0.5         0.0  \n",
       "3     0.000000         0.0         0.0  \n",
       "4     0.000000         0.0         0.0  \n",
       "..         ...         ...         ...  \n",
       "25    0.000000         0.0         0.0  \n",
       "26    0.000000         0.0         0.0  \n",
       "27    0.738835         0.0         0.0  \n",
       "28    0.000000         0.0         0.0  \n",
       "29    0.000000         0.0         0.0  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val = ngram_vectorize(shuffled_train_df['essay'], shuffled_train_df['labels'], shuffled_test_df['essay'])\n",
    "\n",
    "x_val.shape\n",
    "x_val.toarray()\n",
    "vectorized_train_df = pd.DataFrame(x_train.toarray())\n",
    "vectorized_val_df = pd.DataFrame(x_val.toarray())\n",
    "\n",
    "vectorized_df = pd.concat([vectorized_train_df, vectorized_val_df])\n",
    "\n",
    "for i in range(len(vectorized_df.columns)):\n",
    "    vectorized_df.rename(columns={vectorized_df.columns[i]: f\"feature_{i}\"}, inplace=True)\n",
    "vectorized_df.rename({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>source</th>\n",
       "      <th>essay</th>\n",
       "      <th>labels</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Americans in the Revolutionary Era</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>The American Revolution is typically depicted ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Legalization of Marijuana in the United States</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>150</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Legalization of marijuana in the United States...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inclusive Educationâ€™ Benefits</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Inclusive education is a type of education sys...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commercial Uses of Data Mining</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>Data mining is a computer-based classification...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mathematics â€“ Concept of Multiplication</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>In understanding multiplication, it is essenti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      essay_title           type  \\\n",
       "0        Black Americans in the Revolutionary Era     Expository   \n",
       "1  Legalization of Marijuana in the United States  Argumentative   \n",
       "2                   Inclusive Educationâ€™ Benefits  Argumentative   \n",
       "3                  Commercial Uses of Data Mining     Expository   \n",
       "4         Mathematics â€“ Concept of Multiplication     Expository   \n",
       "\n",
       "   min_word_count         source  \\\n",
       "0             800  human_written   \n",
       "1             150     ai_written   \n",
       "2             800     ai_written   \n",
       "3             800  human_written   \n",
       "4             800  human_written   \n",
       "\n",
       "                                               essay  labels  feature_0  \\\n",
       "0  The American Revolution is typically depicted ...       1        0.0   \n",
       "1  Legalization of marijuana in the United States...       0        0.0   \n",
       "2  Inclusive education is a type of education sys...       0        0.0   \n",
       "3  Data mining is a computer-based classification...       1        0.0   \n",
       "4  In understanding multiplication, it is essenti...       1        0.0   \n",
       "\n",
       "   feature_1  feature_2  feature_3  ...  feature_5  feature_6  feature_7  \\\n",
       "0        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "2        0.5        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "\n",
       "   feature_8  feature_9  feature_10  feature_11  feature_12  feature_13  \\\n",
       "0        0.0        0.0         0.0         0.0         0.0         0.0   \n",
       "1        0.0        0.0         0.0         0.0         0.0         0.0   \n",
       "2        0.5        0.0         0.0         0.0         0.0         0.5   \n",
       "3        0.0        0.0         0.0         0.0         0.0         0.0   \n",
       "4        0.0        0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   feature_14  \n",
       "0         0.0  \n",
       "1         1.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all columns with all zeros\n",
    "vectorized_df = vectorized_df.loc[:, (vectorized_df != 0).any(axis=0)]\n",
    "\n",
    "shuffled_df = pd.concat([shuffled_train_df, shuffled_test_df])\n",
    "\n",
    "finalized_features_df = pd.concat([shuffled_df, vectorized_df], axis=1)\n",
    "\n",
    "finalized_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>source</th>\n",
       "      <th>essay</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adaptive Immunity: T-Cells and B-Cells</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>150</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Adaptive immunity is a type of immune response...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advertising Ethics in the Modern Consumer Soci...</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Advertising is an essential aspect of modern c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>0.321088</td>\n",
       "      <td>0.331598</td>\n",
       "      <td>0.303183</td>\n",
       "      <td>0.321088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663195</td>\n",
       "      <td>0.281665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Health Care System</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>The American health care system is a complex a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arranged Marriage and Its Ethical Dilemma</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Arranged marriage has been a longstanding prac...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assistive Technology for Kids with Learning Di...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Children with learning disabilities often face...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         essay_title           type  \\\n",
       "0             Adaptive Immunity: T-Cells and B-Cells  Argumentative   \n",
       "1  Advertising Ethics in the Modern Consumer Soci...  Argumentative   \n",
       "2                        American Health Care System     Expository   \n",
       "3          Arranged Marriage and Its Ethical Dilemma  Argumentative   \n",
       "4  Assistive Technology for Kids with Learning Di...     Expository   \n",
       "\n",
       "   min_word_count      source  \\\n",
       "0             150  ai_written   \n",
       "1             800  ai_written   \n",
       "2             800  ai_written   \n",
       "3             800  ai_written   \n",
       "4             800  ai_written   \n",
       "\n",
       "                                               essay  feature_0  feature_1  \\\n",
       "0  Adaptive immunity is a type of immune response...        0.0        0.0   \n",
       "1  Advertising is an essential aspect of modern c...        0.0        0.0   \n",
       "2  The American health care system is a complex a...        0.0        0.0   \n",
       "3  Arranged marriage has been a longstanding prac...        0.0        0.0   \n",
       "4  Children with learning disabilities often face...        0.0        0.0   \n",
       "\n",
       "   feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  \\\n",
       "0   0.000000   0.000000   0.000000   0.000000   0.000000        0.0   \n",
       "1   0.269750   0.321088   0.331598   0.303183   0.321088        0.0   \n",
       "2   0.000000   0.000000   0.000000   0.256340   0.000000        0.0   \n",
       "3   0.000000   0.000000   1.000000   0.000000   0.000000        0.0   \n",
       "4   0.631054   0.000000   0.775739   0.000000   0.000000        0.0   \n",
       "\n",
       "   feature_8  feature_9  feature_10  feature_11  feature_12  feature_13  \\\n",
       "0        0.0   0.000000    0.000000         0.0         0.0         0.0   \n",
       "1        0.0   0.663195    0.281665         0.0         0.0         0.0   \n",
       "2        0.0   0.000000    0.476292         0.0         0.0         0.0   \n",
       "3        0.0   0.000000    0.000000         0.0         0.0         0.0   \n",
       "4        0.0   0.000000    0.000000         0.0         0.0         0.0   \n",
       "\n",
       "   feature_14  \n",
       "0    0.000000  \n",
       "1    0.000000  \n",
       "2    0.841092  \n",
       "3    0.000000  \n",
       "4    0.000000  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by source\n",
    "finalized_features_df = finalized_features_df.sort_values(by=['source', 'essay_title']).reset_index().drop(['index', 'labels'], axis=1)\n",
    "finalized_features_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, df, class_col):\n",
    "        #do something\n",
    "        #you *may* want to cache every possible query for cond_prof. Up to you.\n",
    "        self.df = df\n",
    "        self.class_col = class_col\n",
    "\n",
    "    # ex: cond_prof('cap_color','r','e') => P(cap_color==red|edible)\n",
    "    @functools.lru_cache(maxsize=2048)\n",
    "    def cond_prob(self, feature_col, feature_value, class_value):\n",
    "        #  return P(feature_col==feature_value | class_col==class_value)\n",
    "        feature = self.df[feature_col] == feature_value\n",
    "        class_for_prob = self.df[self.class_col] == class_value\n",
    "        return len(self.df[feature & class_for_prob]) / len(self.df[class_for_prob])\n",
    "\n",
    "    # P(everthing | p)\n",
    "    @functools.lru_cache(maxsize=2048)\n",
    "    def conditional_term(self, essay, class_val):\n",
    "        conditional_prob = 1\n",
    "        for column in self.df.columns:\n",
    "#             print(column)\n",
    "            if column != self.class_col:\n",
    "                col_val = getattr(essay, column)\n",
    "                conditional_prob *= self.cond_prob(column, col_val, class_val)\n",
    "        return conditional_prob\n",
    "\n",
    "    # P(class_value) alone\n",
    "    @functools.lru_cache(maxsize=2048)\n",
    "    def prior(self, class_value):\n",
    "        return len(self.df[self.df[self.class_col] == class_value]) / len(self.df)\n",
    "  \n",
    "    #mushroom is stuff you got from itertuple\n",
    "    # return P(edible | all mushroom features)\n",
    "    def prob_ai(self, essay):\n",
    "        ai_written_conditional = self.conditional_term(essay, 'ai_written')\n",
    "        human_written_conditional = self.conditional_term(essay, 'human_written')\n",
    "        ai_written_prior = self.prior('ai_written') # P(AW)\n",
    "        human_written_prior = self.prior('human_written') # P(HW)\n",
    "        evidence = (ai_written_conditional * ai_written_prior) + (human_written_conditional * human_written_prior)\n",
    "        return (ai_written_conditional * ai_written_prior) / evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayes(finalized_features_df, 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_cond = 1e-11\n",
    "human = 0\n",
    "ai = 0\n",
    "for i in finalized_features_df.itertuples():\n",
    "    prob_ai = classifier.conditional_term(i, 'ai_written')\n",
    "    if (prob_ai >= ai_cond and i.source == 'ai_written'):\n",
    "        ai += 1\n",
    "    elif (prob_ai < ai_cond and i.source == 'human_written'):\n",
    "        human += 1\n",
    "        \n",
    "human + ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666666666666"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "139 / 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
