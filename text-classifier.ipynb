{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functools\n",
    "import keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7138/3146159652.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns \\\n",
      "/tmp/ipykernel_7138/3146159652.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>human_written</th>\n",
       "      <th>ai_written</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>max_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pneumonia: Differential Diagnosis and Primary ...</td>\n",
       "      <td>Penetration of pathogens of pneumonia in the r...</td>\n",
       "      <td>Pneumonia is a common respiratory infection th...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relevance and Significance of Communication Te...</td>\n",
       "      <td>The relevance and significance of communicatio...</td>\n",
       "      <td>Communication technology has become an integra...</td>\n",
       "      <td>Persuasive</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technological Objects and Their Capabilities</td>\n",
       "      <td>An innovative home system is one of the unique...</td>\n",
       "      <td>Technological objects have become an integral ...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philosophy Teaching and Learning Motivation</td>\n",
       "      <td>Teaching and learning philosophy can be a chal...</td>\n",
       "      <td>Teaching and learning philosophy can be a chal...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buddhism and Hinduism: Religious Differences</td>\n",
       "      <td>Buddhism and Hinduism have the same roots. Nev...</td>\n",
       "      <td>Buddhism and Hinduism are two major religions ...</td>\n",
       "      <td>Compare &amp; Contrast</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         essay_title  \\\n",
       "0  Pneumonia: Differential Diagnosis and Primary ...   \n",
       "1  Relevance and Significance of Communication Te...   \n",
       "2      Technological Objects and Their Capabilities    \n",
       "3        Philosophy Teaching and Learning Motivation   \n",
       "4       Buddhism and Hinduism: Religious Differences   \n",
       "\n",
       "                                       human_written  \\\n",
       "0  Penetration of pathogens of pneumonia in the r...   \n",
       "1  The relevance and significance of communicatio...   \n",
       "2  An innovative home system is one of the unique...   \n",
       "3  Teaching and learning philosophy can be a chal...   \n",
       "4  Buddhism and Hinduism have the same roots. Nev...   \n",
       "\n",
       "                                          ai_written                type  \\\n",
       "0  Pneumonia is a common respiratory infection th...          Expository   \n",
       "1  Communication technology has become an integra...          Persuasive   \n",
       "2  Technological objects have become an integral ...          Expository   \n",
       "3  Teaching and learning philosophy can be a chal...          Expository   \n",
       "4  Buddhism and Hinduism are two major religions ...  Compare & Contrast   \n",
       "\n",
       "   min_word_count  max_word_count  \n",
       "0             150             200  \n",
       "1             150             200  \n",
       "2             150             200  \n",
       "3             150             200  \n",
       "4             150             200  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_WORD_COUNT = 'Min Word Count'\n",
    "MAX_WORD_COUNT = 'Max Word Count'\n",
    "\n",
    "df200 = pd.read_csv('resources/essays200.csv').drop('Unnamed: 4', axis=1)\n",
    "df200[MIN_WORD_COUNT] = 150\n",
    "df200[MAX_WORD_COUNT] = 200\n",
    "df500 = pd.read_csv('resources/essays500.csv').drop('Unnamed: 4', axis=1) \n",
    "df500[MIN_WORD_COUNT] = 500\n",
    "df500[MAX_WORD_COUNT] = 600\n",
    "df1000 = pd.read_csv('resources/essays1000.csv').drop('Unnamed: 4', axis=1)\n",
    "df1000[MIN_WORD_COUNT] = 800\n",
    "df1000[MAX_WORD_COUNT] = 1200\n",
    "\n",
    "df = pd.concat([df200, df500, df1000])\n",
    "df.columns = df.columns \\\n",
    "    .str.strip() \\\n",
    "    .str.lower() \\\n",
    "    .str.replace(' ', '_') \\\n",
    "    .str.replace('(', '') \\\n",
    "    .str.replace(')', '') \\\n",
    "    .str.replace('-','_') \\\n",
    "    .map(lambda x: 'x'+x if x in keyword.kwlist else x )\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_df = df.melt(id_vars=['essay_title', 'type', 'min_word_count'], value_vars=['human_written', 'ai_written'], var_name='source', value_name='essay')\n",
    "\n",
    "def convert_label(label):\n",
    "    return 1 if label == 'human_written' else 0\n",
    "\n",
    "melted_df['labels'] = melted_df['source'].apply(convert_label)\n",
    "\n",
    "melted_df = melted_df.sort_values(by=['source', 'essay_title']).reset_index()\n",
    "melted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>source</th>\n",
       "      <th>essay</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanchard and Fiedler Leadership Models</td>\n",
       "      <td>Expository</td>\n",
       "      <td>500</td>\n",
       "      <td>human_written</td>\n",
       "      <td>As opposed to Taylorists who opined that there...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy and Environmental Policies</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>Laws are meant to regulate how people behave t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moral issue in business</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>Privacy has been identified to be an integral ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Relevance and Significance of Communication Te...</td>\n",
       "      <td>Persuasive</td>\n",
       "      <td>150</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Communication technology has become an integra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Concepts of the Baroque Era</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>The Baroque era was a period in the art histor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         essay_title        type  \\\n",
       "0            Blanchard and Fiedler Leadership Models  Expository   \n",
       "1                  Energy and Environmental Policies  Expository   \n",
       "2                           Moral issue in business   Analytical   \n",
       "3  Relevance and Significance of Communication Te...  Persuasive   \n",
       "4                        Concepts of the Baroque Era  Expository   \n",
       "\n",
       "   min_word_count         source  \\\n",
       "0             500  human_written   \n",
       "1             800  human_written   \n",
       "2             800  human_written   \n",
       "3             150     ai_written   \n",
       "4             800  human_written   \n",
       "\n",
       "                                               essay  labels  \n",
       "0  As opposed to Taylorists who opined that there...       1  \n",
       "1  Laws are meant to regulate how people behave t...       1  \n",
       "2  Privacy has been identified to be an integral ...       1  \n",
       "3  Communication technology has become an integra...       0  \n",
       "4  The Baroque era was a period in the art histor...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([melted_df[:60], melted_df[75:135]])\n",
    "test_df = pd.concat([melted_df[60:75], melted_df[135:]])\n",
    "\n",
    "shuffled_train_df = train_df.sample(frac=1).reset_index().drop(['index', 'level_0'], axis=1)\n",
    "shuffled_test_df = test_df.sample(frac=1).reset_index().drop(['index', 'level_0'], axis=1)\n",
    "shuffled_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "NGRAM_RANGE = (2, 3)\n",
    "\n",
    "TOP_K = 25000\n",
    "\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "MIN_DOCUMENT_FREQUENCY = 4\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
    "    \"\"\"Vectorizes texts as n-gram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE, \n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE, \n",
    "            'stop_words': 'english',\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    x_val = vectorizer.transform(val_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train).astype('float32')\n",
    "    x_val = selector.transform(x_val).astype('float32')\n",
    "    return x_train, x_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhavni/.pyenv/versions/3.9.10/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2070: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7138/3706744550.py:11: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  vectorized_train_df = vectorized_train_df[intersecting_columns]\n",
      "/tmp/ipykernel_7138/3706744550.py:12: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  vectorized_test_df = vectorized_test_df[intersecting_columns]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val = ngram_vectorize(shuffled_train_df['essay'], shuffled_train_df['labels'], shuffled_test_df['essay'])\n",
    "\n",
    "def to_vector(x):\n",
    "    df = pd.DataFrame(x.toarray())\n",
    "    return df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "vectorized_train_df = to_vector(x_train)\n",
    "vectorized_test_df = to_vector(x_val)\n",
    "\n",
    "intersecting_columns = set(vectorized_train_df.columns) & set(vectorized_test_df.columns)\n",
    "vectorized_train_df = vectorized_train_df[intersecting_columns]\n",
    "vectorized_test_df = vectorized_test_df[intersecting_columns]\n",
    "\n",
    "print(len(vectorized_train_df.columns))\n",
    "\n",
    "# len(vectorized_test_df.columns)\n",
    "\n",
    "def concatenate_and_cleanup(shuffled_df, vectorized_df):\n",
    "    vectorized_df = vectorized_df.reindex(sorted(vectorized_df.columns), axis=1)\n",
    "\n",
    "    for i in range(len(vectorized_df.columns)):\n",
    "        vectorized_df.rename(columns={vectorized_df.columns[i]: f\"feature_{i}\"}, inplace=True)\n",
    "    \n",
    "    df = pd.concat([shuffled_df, vectorized_df], axis=1)\n",
    "\n",
    "    return df.sort_values(by=['source', 'essay_title']).reset_index().drop(['index', 'labels'], axis=1)\n",
    "\n",
    "train_df_with_features = concatenate_and_cleanup(shuffled_train_df, vectorized_train_df)\n",
    "test_df_with_features =  concatenate_and_cleanup(shuffled_test_df, vectorized_test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>feature_40</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257980</td>\n",
       "      <td>0.171062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  min_word_count  feature_0  feature_1  feature_2  feature_3  \\\n",
       "0     4             150        0.0        0.0        0.0        0.0   \n",
       "1     4             800        0.0        0.0        0.0        0.0   \n",
       "2     5             800        0.0        0.0        0.0        0.0   \n",
       "3     4             800        0.0        0.0        0.0        0.0   \n",
       "4     5             800        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   feature_4  feature_5  feature_6  feature_7  ...  feature_36  feature_37  \\\n",
       "0        0.0        0.0        0.0        0.0  ...    0.000000         0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...    0.000000         0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...    0.000000         0.0   \n",
       "3        0.0        0.0        0.0        0.0  ...    0.000000         0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...    0.257736         0.0   \n",
       "\n",
       "   feature_38  feature_39  feature_40  feature_41  feature_42  feature_43  \\\n",
       "0    0.000000    0.000000    0.000000    0.000000         0.0    0.000000   \n",
       "1    0.364311    0.000000    0.154726    0.000000         0.0    0.205192   \n",
       "2    0.000000    0.000000    0.257980    0.171062         0.0    0.000000   \n",
       "3    0.000000    0.000000    0.000000    0.000000         0.0    0.000000   \n",
       "4    0.000000    0.515472    0.000000    0.000000         0.0    0.000000   \n",
       "\n",
       "   feature_44  feature_45  \n",
       "0         0.0    0.000000  \n",
       "1         0.0    0.000000  \n",
       "2         0.0    0.455571  \n",
       "3         0.0    0.000000  \n",
       "4         0.0    0.000000  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "\n",
    "essay_types = {\n",
    "    'Analytical': 0,\n",
    "    'Compare & Contrast': 1,\n",
    "    'Personal': 2,\n",
    "    'Persuasive': 3,\n",
    "    'Argumentative': 4,\n",
    "    'Expository': 5,\n",
    "}\n",
    "\n",
    "def drop_non_features(df):\n",
    "    df = df.copy()\n",
    "    df['type'] = df['type'].apply(lambda x: essay_types[x])\n",
    "    return df.drop(['essay_title', 'essay', 'source'], axis=1)\n",
    "\n",
    "\n",
    "X_train, y_train = drop_non_features(train_df_with_features), train_df_with_features['source'] == 'ai_written'\n",
    "\n",
    "# y_train\n",
    "X_test, y_test = drop_non_features(test_df_with_features), test_df_with_features['source'] == 'ai_written'\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "count_correct = 0\n",
    "\n",
    "for pred, corr in zip(y_pred, y_test):\n",
    "    if pred == corr:\n",
    "        count_correct += 1\n",
    "\n",
    "count_correct / len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
