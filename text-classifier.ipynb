{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functools\n",
    "import keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4906/3146159652.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns \\\n",
      "/tmp/ipykernel_4906/3146159652.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>human_written</th>\n",
       "      <th>ai_written</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>max_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pneumonia: Differential Diagnosis and Primary ...</td>\n",
       "      <td>Penetration of pathogens of pneumonia in the r...</td>\n",
       "      <td>Pneumonia is a common respiratory infection th...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relevance and Significance of Communication Te...</td>\n",
       "      <td>The relevance and significance of communicatio...</td>\n",
       "      <td>Communication technology has become an integra...</td>\n",
       "      <td>Persuasive</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technological Objects and Their Capabilities</td>\n",
       "      <td>An innovative home system is one of the unique...</td>\n",
       "      <td>Technological objects have become an integral ...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philosophy Teaching and Learning Motivation</td>\n",
       "      <td>Teaching and learning philosophy can be a chal...</td>\n",
       "      <td>Teaching and learning philosophy can be a chal...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buddhism and Hinduism: Religious Differences</td>\n",
       "      <td>Buddhism and Hinduism have the same roots. Nev...</td>\n",
       "      <td>Buddhism and Hinduism are two major religions ...</td>\n",
       "      <td>Compare &amp; Contrast</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         essay_title  \\\n",
       "0  Pneumonia: Differential Diagnosis and Primary ...   \n",
       "1  Relevance and Significance of Communication Te...   \n",
       "2      Technological Objects and Their Capabilities    \n",
       "3        Philosophy Teaching and Learning Motivation   \n",
       "4       Buddhism and Hinduism: Religious Differences   \n",
       "\n",
       "                                       human_written  \\\n",
       "0  Penetration of pathogens of pneumonia in the r...   \n",
       "1  The relevance and significance of communicatio...   \n",
       "2  An innovative home system is one of the unique...   \n",
       "3  Teaching and learning philosophy can be a chal...   \n",
       "4  Buddhism and Hinduism have the same roots. Nev...   \n",
       "\n",
       "                                          ai_written                type  \\\n",
       "0  Pneumonia is a common respiratory infection th...          Expository   \n",
       "1  Communication technology has become an integra...          Persuasive   \n",
       "2  Technological objects have become an integral ...          Expository   \n",
       "3  Teaching and learning philosophy can be a chal...          Expository   \n",
       "4  Buddhism and Hinduism are two major religions ...  Compare & Contrast   \n",
       "\n",
       "   min_word_count  max_word_count  \n",
       "0             150             200  \n",
       "1             150             200  \n",
       "2             150             200  \n",
       "3             150             200  \n",
       "4             150             200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_WORD_COUNT = 'Min Word Count'\n",
    "MAX_WORD_COUNT = 'Max Word Count'\n",
    "\n",
    "df200 = pd.read_csv('resources/essays200.csv').drop('Unnamed: 4', axis=1)\n",
    "df200[MIN_WORD_COUNT] = 150\n",
    "df200[MAX_WORD_COUNT] = 200\n",
    "df500 = pd.read_csv('resources/essays500.csv').drop('Unnamed: 4', axis=1) \n",
    "df500[MIN_WORD_COUNT] = 500\n",
    "df500[MAX_WORD_COUNT] = 600\n",
    "df1000 = pd.read_csv('resources/essays1000.csv').drop('Unnamed: 4', axis=1)\n",
    "df1000[MIN_WORD_COUNT] = 800\n",
    "df1000[MAX_WORD_COUNT] = 1200\n",
    "\n",
    "df = pd.concat([df200, df500, df1000])\n",
    "df.columns = df.columns \\\n",
    "    .str.strip() \\\n",
    "    .str.lower() \\\n",
    "    .str.replace(' ', '_') \\\n",
    "    .str.replace('(', '') \\\n",
    "    .str.replace(')', '') \\\n",
    "    .str.replace('-','_') \\\n",
    "    .map(lambda x: 'x'+x if x in keyword.kwlist else x )\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_df = df.melt(id_vars=['essay_title', 'type', 'min_word_count'], value_vars=['human_written', 'ai_written'], var_name='source', value_name='essay')\n",
    "\n",
    "def convert_label(label):\n",
    "    return 1 if label == 'human_written' else 0\n",
    "\n",
    "melted_df['labels'] = melted_df['source'].apply(convert_label)\n",
    "\n",
    "melted_df = melted_df.sort_values(by=['source', 'essay_title']).reset_index()\n",
    "melted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>source</th>\n",
       "      <th>essay</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quality Management for Organizational Excellence</td>\n",
       "      <td>Expository</td>\n",
       "      <td>500</td>\n",
       "      <td>human_written</td>\n",
       "      <td>Quality management is a continuous organizatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black Americans in the Revolutionary Era</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>human_written</td>\n",
       "      <td>The American Revolution is typically depicted ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medical Uses of Marijuana</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>500</td>\n",
       "      <td>human_written</td>\n",
       "      <td>Marijuana is medicinal extracts from a plant k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blanchard and Fiedler Leadership Models</td>\n",
       "      <td>Expository</td>\n",
       "      <td>500</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Leadership is a complex and multifaceted conce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Employee Performance Software and Its Benefits</td>\n",
       "      <td>Expository</td>\n",
       "      <td>150</td>\n",
       "      <td>human_written</td>\n",
       "      <td>The implementation of Employee Performance Sof...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        essay_title        type  \\\n",
       "0  Quality Management for Organizational Excellence  Expository   \n",
       "1          Black Americans in the Revolutionary Era  Expository   \n",
       "2                         Medical Uses of Marijuana  Analytical   \n",
       "3           Blanchard and Fiedler Leadership Models  Expository   \n",
       "4    Employee Performance Software and Its Benefits  Expository   \n",
       "\n",
       "   min_word_count         source  \\\n",
       "0             500  human_written   \n",
       "1             800  human_written   \n",
       "2             500  human_written   \n",
       "3             500     ai_written   \n",
       "4             150  human_written   \n",
       "\n",
       "                                               essay  labels  \n",
       "0  Quality management is a continuous organizatio...       1  \n",
       "1  The American Revolution is typically depicted ...       1  \n",
       "2  Marijuana is medicinal extracts from a plant k...       1  \n",
       "3  Leadership is a complex and multifaceted conce...       0  \n",
       "4  The implementation of Employee Performance Sof...       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([melted_df[:60], melted_df[75:135]])\n",
    "test_df = pd.concat([melted_df[60:75], melted_df[135:]])\n",
    "\n",
    "shuffled_train_df = train_df.sample(frac=1).reset_index().drop(['index', 'level_0'], axis=1)\n",
    "shuffled_test_df = test_df.sample(frac=1).reset_index().drop(['index', 'level_0'], axis=1)\n",
    "shuffled_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "NGRAM_RANGE = (2, 7)\n",
    "\n",
    "TOP_K = 15000\n",
    "\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "MIN_DOCUMENT_FREQUENCY = 6\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
    "    \"\"\"Vectorizes texts as n-gram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE, \n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE, \n",
    "            'stop_words': 'english',\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    x_val = vectorizer.transform(val_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train).astype('float32')\n",
    "    x_val = selector.transform(x_val).astype('float32')\n",
    "    return x_train, x_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhavni/.pyenv/versions/3.9.10/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2070: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_4906/555750000.py:11: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  vectorized_train_df = vectorized_train_df[intersecting_columns]\n",
      "/tmp/ipykernel_4906/555750000.py:12: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  vectorized_test_df = vectorized_test_df[intersecting_columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_title</th>\n",
       "      <th>type</th>\n",
       "      <th>min_word_count</th>\n",
       "      <th>source</th>\n",
       "      <th>essay</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adaptive Immunity: T-Cells and B-Cells</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>150</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Adaptive immunity is a type of immune response...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advertising Ethics in the Modern Consumer Soci...</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Advertising is an essential aspect of modern c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242634</td>\n",
       "      <td>0.308982</td>\n",
       "      <td>0.298265</td>\n",
       "      <td>0.272706</td>\n",
       "      <td>0.288812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596529</td>\n",
       "      <td>0.253351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Health Care System</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>The American health care system is a complex a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arranged Marriage and Its Ethical Dilemma</td>\n",
       "      <td>Argumentative</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Arranged marriage has been a longstanding prac...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assistive Technology for Kids with Learning Di...</td>\n",
       "      <td>Expository</td>\n",
       "      <td>800</td>\n",
       "      <td>ai_written</td>\n",
       "      <td>Children with learning disabilities often face...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         essay_title           type  \\\n",
       "0             Adaptive Immunity: T-Cells and B-Cells  Argumentative   \n",
       "1  Advertising Ethics in the Modern Consumer Soci...  Argumentative   \n",
       "2                        American Health Care System     Expository   \n",
       "3          Arranged Marriage and Its Ethical Dilemma  Argumentative   \n",
       "4  Assistive Technology for Kids with Learning Di...     Expository   \n",
       "\n",
       "   min_word_count      source  \\\n",
       "0             150  ai_written   \n",
       "1             800  ai_written   \n",
       "2             800  ai_written   \n",
       "3             800  ai_written   \n",
       "4             800  ai_written   \n",
       "\n",
       "                                               essay  feature_0  feature_1  \\\n",
       "0  Adaptive immunity is a type of immune response...        0.0        0.0   \n",
       "1  Advertising is an essential aspect of modern c...        0.0        0.0   \n",
       "2  The American health care system is a complex a...        0.0        0.0   \n",
       "3  Arranged marriage has been a longstanding prac...        0.0        0.0   \n",
       "4  Children with learning disabilities often face...        0.0        0.0   \n",
       "\n",
       "   feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  \\\n",
       "0   0.000000   0.000000   0.000000   0.000000   0.000000        0.0   \n",
       "1   0.242634   0.308982   0.298265   0.272706   0.288812        0.0   \n",
       "2   0.000000   0.000000   0.000000   0.256340   0.000000        0.0   \n",
       "3   0.000000   0.000000   1.000000   0.000000   0.000000        0.0   \n",
       "4   0.631054   0.000000   0.775739   0.000000   0.000000        0.0   \n",
       "\n",
       "   feature_8  feature_9  feature_10  feature_11  feature_12  \n",
       "0        0.0   0.000000    0.000000         0.0    0.000000  \n",
       "1        0.0   0.596529    0.253351         0.0    0.000000  \n",
       "2        0.0   0.000000    0.476292         0.0    0.841092  \n",
       "3        0.0   0.000000    0.000000         0.0    0.000000  \n",
       "4        0.0   0.000000    0.000000         0.0    0.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val = ngram_vectorize(shuffled_train_df['essay'], shuffled_train_df['labels'], shuffled_test_df['essay'])\n",
    "\n",
    "def to_vector(x):\n",
    "    df = pd.DataFrame(x.toarray())\n",
    "    return df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "vectorized_train_df = to_vector(x_train)\n",
    "vectorized_test_df = to_vector(x_val)\n",
    "\n",
    "intersecting_columns = set(vectorized_train_df.columns) & set(vectorized_test_df.columns)\n",
    "vectorized_train_df = vectorized_train_df[intersecting_columns]\n",
    "vectorized_test_df = vectorized_test_df[intersecting_columns]\n",
    "\n",
    "# len(vectorized_test_df.columns)\n",
    "\n",
    "def concatenate_and_cleanup(shuffled_df, vectorized_df):\n",
    "    vectorized_df = vectorized_df.reindex(sorted(vectorized_df.columns), axis=1)\n",
    "\n",
    "    for i in range(len(vectorized_df.columns)):\n",
    "        vectorized_df.rename(columns={vectorized_df.columns[i]: f\"feature_{i}\"}, inplace=True)\n",
    "    \n",
    "    df = pd.concat([shuffled_df, vectorized_df], axis=1)\n",
    "\n",
    "    return df.sort_values(by=['source', 'essay_title']).reset_index().drop(['index', 'labels'], axis=1)\n",
    "\n",
    "vectorized_train_df_with_features = concatenate_and_cleanup(shuffled_train_df, vectorized_train_df)\n",
    "vectorized_test_df_with_features =  concatenate_and_cleanup(shuffled_test_df, vectorized_test_df)\n",
    "\n",
    "vectorized_train_df_with_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, df, class_col):\n",
    "        #do something\n",
    "        #you *may* want to cache every possible query for cond_prof. Up to you.\n",
    "        self.df = df\n",
    "        self.class_col = class_col\n",
    "\n",
    "    # ex: cond_prof('cap_color','r','e') => P(cap_color==red|edible)\n",
    "    @functools.lru_cache(maxsize=2048)\n",
    "    def cond_prob(self, feature_col, feature_value, class_value):\n",
    "        #  return P(feature_col==feature_value | class_col==class_value)\n",
    "        feature = self.df[feature_col] == feature_value\n",
    "        class_for_prob = self.df[self.class_col] == class_value\n",
    "        return len(self.df[feature & class_for_prob]) / len(self.df[class_for_prob])\n",
    "\n",
    "    # P(everthing | p)\n",
    "    @functools.lru_cache(maxsize=2048)\n",
    "    def conditional_term(self, essay, class_val):\n",
    "        conditional_prob = 1\n",
    "        for column in self.df.columns:\n",
    "#             print(column)\n",
    "            if column != self.class_col:\n",
    "                col_val = getattr(essay, column)\n",
    "                conditional_prob *= self.cond_prob(column, col_val, class_val)\n",
    "        return conditional_prob\n",
    "\n",
    "    # P(class_value) alone\n",
    "    @functools.lru_cache(maxsize=2048)\n",
    "    def prior(self, class_value):\n",
    "        return len(self.df[self.df[self.class_col] == class_value]) / len(self.df)\n",
    "  \n",
    "    #mushroom is stuff you got from itertuple\n",
    "    # return P(edible | all mushroom features)\n",
    "    def prob_ai(self, essay):\n",
    "        ai_written_conditional = self.conditional_term(essay, 'ai_written')\n",
    "        human_written_conditional = self.conditional_term(essay, 'human_written')\n",
    "        ai_written_prior = self.prior('ai_written') # P(AW)\n",
    "        human_written_prior = self.prior('human_written') # P(HW)\n",
    "        evidence = (ai_written_conditional * ai_written_prior) + (human_written_conditional * human_written_prior)\n",
    "        return (ai_written_conditional * ai_written_prior) / evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayes(finalized_features_df, 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_cond = 1e-11\n",
    "human = 0\n",
    "ai = 0\n",
    "for i in finalized_features_df.itertuples():\n",
    "    prob_ai = classifier.conditional_term(i, 'ai_written')\n",
    "    if (prob_ai >= ai_cond and i.source == 'ai_written'):\n",
    "        ai += 1\n",
    "    elif (prob_ai < ai_cond and i.source == 'human_written'):\n",
    "        human += 1\n",
    "        \n",
    "human + ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666666666666"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "139 / 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
